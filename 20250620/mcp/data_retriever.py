import json
from datetime import datetime
from collections import defaultdict
from qdrant_client.http.models import Filter, FieldCondition, MatchValue, Range, SearchRequest, NamedVector
from .utils import get_embedding_models, get_qdrant_client, get_openai_client, parse_natural_date


def expand_keywords(keyword: str, product_type: str = None):
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ í‚¤ì›Œë“œë¥¼ í™•ì¥í•©ë‹ˆë‹¤.
    1. ìƒí™©/ê²½í—˜ ê¸°ë°˜ì˜ ë¬¸ì¥
    2. ìœ ì‚¬/ì—°ê´€ì–´ ê¸°ë°˜ì˜ ë¬¸ì¥
    ë‘ ì¢…ë¥˜ë¥¼ ëª¨ë‘ ìƒì„±í•˜ë„ë¡ ê³ ë„í™”ë˜ì—ˆìŠµë‹ˆë‹¤.
    """
    client = get_openai_client()
    product_context = f"ğŸ§° ì œí’ˆ ì¹´í…Œê³ ë¦¬: {product_type}\nì´ ë§¥ë½ì„ ë°˜ì˜í•˜ì—¬ ì•„ë˜ ë‚´ìš©ì„ ìƒì„±í•´ì£¼ì„¸ìš”." if product_type else ""
    
    if product_type == None:
        product_context = ""

    # [ìˆ˜ì •ëœ í”„ë¡¬í”„íŠ¸]
    prompt = f"""
    ë‹¹ì‹ ì€ ì†Œë¹„ì ì–¸ì–´ì™€ ì œí’ˆì˜ ê¸°ìˆ  ìš©ì–´ë¥¼ ëª¨ë‘ ì´í•´í•˜ëŠ” ì†Œë¹„ì ì¸ì‚¬ì´íŠ¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì•„ë˜ ì£¼ì–´ì§„ ê¸°ëŠ¥ í‚¤ì›Œë“œì™€ ê´€ë ¨í•˜ì—¬, ë‹¤ìŒ ë‘ ê°€ì§€ ì¢…ë¥˜ì˜ ì†Œë¹„ì í‘œí˜„ì„ í•©ì³ì„œ 10~12ê°œ ìƒì„±í•´ì£¼ì„¸ìš”.

    **ê¸°ëŠ¥ í‚¤ì›Œë“œ: "{keyword}"**
    {product_context}
    ---

    ### 1. ìƒí™©/ê²½í—˜/ë‹ˆì¦ˆë¥¼ í‘œí˜„í•˜ëŠ” ë¬¸ì¥ (5~6ê°œ)
    - ì†Œë¹„ìëŠ” "{keyword}"ë¼ëŠ” ë‹¨ì–´ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    - í•´ë‹¹ ê¸°ëŠ¥ì´ **í•„ìš”í•œ íŠ¹ì • ìƒí™©, ê²ªê³  ìˆëŠ” ë¶ˆí¸í•¨, ë˜ëŠ” ì–»ê³  ì‹¶ì€ ê°€ì¹˜**ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë¬¸ì¥ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
    - ì˜ˆì‹œ ('ì‚´ê· ' í‚¤ì›Œë“œ): "ì•„ì´ê°€ ì•„í† í”¼ê°€ ìˆì–´ì„œ ì˜·ì„ ë§¤ë²ˆ ì‚¶ì•„ ì…íˆëŠ”ë° ë„ˆë¬´ ë²ˆê±°ë¡œì›Œìš”."

    ### 2. í‚¤ì›Œë“œë¥¼ ë‹¤ë¥¸ ìš©ì–´ë¡œ í‘œí˜„í•˜ëŠ” ë¬¸ì¥ (4~5ê°œ)
    - ì†Œë¹„ìëŠ” "{keyword}" ëŒ€ì‹ , ê´‘ê³ ë‚˜ ì œí’ˆ ìƒì„¸í˜ì´ì§€ì—ì„œ ë³¸ **ìœ ì‚¬ì–´, ì—°ê´€ ê¸°ìˆ /ë§ˆì¼€íŒ… ìš©ì–´**ë¥¼ ì‚¬ìš©í•˜ì—¬ ë§í•˜ê¸°ë„ í•©ë‹ˆë‹¤.
    - ì•„ë˜ ì˜ˆì‹œì²˜ëŸ¼, "{keyword}"ì˜ í•µì‹¬ ê°€ì¹˜ë¥¼ ì „ë‹¬í•˜ëŠ” ë‹¤ë¥¸ í‘œí˜„ì„ ì‚¬ìš©í•œ ë¬¸ì¥ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
    - ì˜ˆì‹œ ('ì‚´ê· ' í‚¤ì›Œë“œ): "ìŠ¤íŒ€ìœ¼ë¡œ 99.9% ì„¸ê· ì„ ë°•ë©¸í•´ì¤€ë‹¤ë‹ˆ ì•ˆì‹¬ë¼ìš”.", "UV ë¨í”„ë¡œ ìœ„ìƒì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆì–´ì„œ ë§ˆìŒì— ë“¤ì–´ìš”."
    
    ---
    **[ê³µí†µ ì œì•½ ì¡°ê±´]**
    - ë‹¨ìˆœ ì¹­ì°¬("ì¢‹ì•„ìš”")ì´ë‚˜ ê°ì • í‘œí˜„ì€ ì§€ì–‘í•´ì£¼ì„¸ìš”.
    - ì‹¤ì œ ì‚¬ìš©ìê°€ ë‚¨ê¸´ í›„ê¸°ë‚˜ ì»¤ë®¤ë‹ˆí‹° ê²Œì‹œê¸€ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬ì—¬ì•¼ í•©ë‹ˆë‹¤.
    - ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ, ê° í•­ëª©ì€ 1ë¬¸ì¥ìœ¼ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”.
    """
    
    try:
        res = client.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}], temperature=0.7)
        expanded_list = [line.strip("-â€¢ ") for line in res.choices[0].message.content.split("\n") if line.strip() and "###" not in line]
        
        # --- [í•µì‹¬ ìˆ˜ì •] ---
        # 1. ì›ë³¸ í‚¤ì›Œë“œë¥¼ ë¦¬ìŠ¤íŠ¸ì˜ ë§¨ ì•ì— ì¶”ê°€í•©ë‹ˆë‹¤.
        # 2. setìœ¼ë¡œ ë³€í™˜í–ˆë‹¤ê°€ ë‹¤ì‹œ listë¡œ ë§Œë“¤ì–´ í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë³µì„ ì œê±°í•©ë‹ˆë‹¤.
        final_keywords = [keyword] + expanded_list
        return list(set(final_keywords))
    except Exception as e:
        print(f"í‚¤ì›Œë“œ í™•ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return [keyword]

def summarize_text(text_to_summarize: str):
    """LLMì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
    client = get_openai_client()
    prompt = f"""
    ë‹¹ì‹ ì€ ì†Œë¹„ì ì–¸ì–´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒì€ ì†Œë¹„ìì˜ ê¸€ ì›ë¬¸ì…ë‹ˆë‹¤.
    ì´ ê¸€ì—ì„œ **ì ì¬ê³ ê°ì˜ ë‹ˆì¦ˆ, ë¶ˆí¸, ìƒí™©, í–‰ë™**ì´ ë“œëŸ¬ë‚˜ëŠ” í•µì‹¬ ë¬¸ì¥ì„ ì¤‘ì‹¬ìœ¼ë¡œ,
    ì›ë¬¸ í‘œí˜„ì„ ìµœëŒ€í•œ ì‚´ë ¤ 3~5ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.
    ì›ë¬¸: {text_to_summarize}
    """
    try:
        res = client.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}], temperature=0.5)
        return res.choices[0].message.content.strip()
    except Exception as e:
        print(f"í…ìŠ¤íŠ¸ ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return text_to_summarize

def run_rrf_search(keywords: list, date_range: tuple | None = None, top_k=50, score_threshold=0.5):
    """RRF ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰"""
    meaning_model, topic_model =get_embedding_models()
    qdrant = get_qdrant_client()
    all_hits_map = {}
    rrf_scores = defaultdict(float)
    K_RRF = 60

    # --- [ì‹ ê·œ] ë‚ ì§œ í•„í„° ìƒì„± ë¡œì§ ---
    must_conditions = []
    if date_range and len(date_range) == 2:
        start_date, end_date = date_range
        print(f"ğŸŒ€ Applying date filter: {start_date} ~ {end_date}")
        must_conditions.append(FieldCondition(
            key="date_timestamp", # ğŸ‘ˆ Qdrantì— ì €ì¥ëœ íƒ€ì„ìŠ¤íƒ¬í”„ í•„ë“œëª…
            range=Range(
                gte=int(datetime.combine(start_date, datetime.min.time()).timestamp()),
                lte=int(datetime.combine(end_date, datetime.max.time()).timestamp())
            )
        ))
    query_filter = Filter(must=must_conditions) if must_conditions else None


    for kw in keywords:
        meaning_vec = meaning_model.encode("query: " + kw)
        topic_vec = topic_model.encode(kw)
        search_results = qdrant.search_batch(
            collection_name="web_data",
            requests=[
                SearchRequest(vector=NamedVector(name="meaning", vector=meaning_vec.tolist()), limit=top_k, with_payload=True, filter=query_filter, score_threshold=score_threshold),
                SearchRequest(vector=NamedVector(name="topic", vector=topic_vec.tolist()), limit=top_k, with_payload=True, filter=query_filter, score_threshold=score_threshold)
            ]
        )
        for hits in search_results:
            for rank, hit in enumerate(hits):
                rrf_scores[hit.id] += 1 / (rank + K_RRF)
                if hit.id not in all_hits_map:
                    all_hits_map[hit.id] = hit

    sorted_hit_ids = sorted(rrf_scores.keys(), key=lambda id: rrf_scores[id], reverse=True)
    results = []
    seen_text = set()
    for hit_id in sorted_hit_ids:
        if len(results) >= top_k: break
        hit = all_hits_map[hit_id]
        original_sentence = hit.payload.get("sentence", "")
        if original_sentence and original_sentence not in seen_text:
            result_payload = hit.payload.copy()
            result_payload['id'] = str(hit.id)
            result_payload['original_text'] = original_sentence
            result_payload['score'] = round(rrf_scores[hit.id], 4)
            result_payload['text'] =  summarize_text(original_sentence) if len(original_sentence) > 150 else original_sentence
            results.append(result_payload)
            seen_text.add(original_sentence)
    return results

#ê¸°ëŠ¥ì •ë³´
def fetch_product_context(product_type: str = None, top_k: int = 20):
    qdrant = get_qdrant_client()
    query_filter = None

    print(f"ğŸ” [Debug] fetch_product_context called with product_type: '{product_type}'")

    # product_typeì´ Noneì´ ì•„ë‹ˆê³  ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹ˆê±°ë‚˜ "(ì„ íƒ ì•ˆí•¨)"ì´ ì•„ë‹ ë•Œë§Œ í•„í„° ì ìš©
    if product_type:
        query_filter = Filter(must=[FieldCondition(key="product_type", match=MatchValue(value=product_type))])
    
    try:
        records, _ = qdrant.scroll(
            collection_name="product_data",
            scroll_filter=query_filter,
            limit=top_k,
            with_payload=True,  # ğŸ‘ˆ ì´ ë¶€ë¶„ì„ Trueë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
        )
        return [record.payload for record in records]
    except Exception as e:
        print(f"ì œí’ˆ ë°ì´í„° ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []
#ì„¼ì„œì •ë³´
def fetch_sensor_context(product_type: str | None, top_k: int = 20): # product_typeì— None í—ˆìš©
    """
    Qdrantì—ì„œ íŠ¹ì • 'Product Category'ì— í•´ë‹¹í•˜ëŠ” ì„¼ì„œ ë°ì´í„° ìƒ˜í”Œì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    qdrant = get_qdrant_client()
    print(f"SENSOR_SEARCH ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿æ¤œç´¢ ğŸ” [Debug] Fetching sensor data for Product Category: '{product_type}'")

    # ğŸš¨ product_typeì´ Noneì´ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¼ ê²½ìš°, ë°ì´í„° ì¡°íšŒë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.
    if not product_type or product_type == '':
        print("SENSOR_SEARCH_SKIP è£½å“ç¾¤ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚ âš ï¸ product_typeì´ ì œê³µë˜ì§€ ì•Šì•„ ì„¼ì„œ ë°ì´í„° ì¡°íšŒë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return []

    try:
        # 'Product Category' í•„ë“œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•„í„° ìƒì„±
        # MatchValueì˜ valueëŠ” Qdrantì— ì €ì¥ëœ ì‹¤ì œ ê°’ê³¼ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
        query_filter = Filter(
            must=[
                FieldCondition(key="Product", match=MatchValue(value=product_type))
            ]
        )

        records, _ = qdrant.scroll(
            collection_name="sensor_data",
            scroll_filter=query_filter,
            limit=top_k,
            with_payload=True,
        )
        
        return [record.payload for record in records]
    except Exception as e:
        # ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì¢€ ë” ëª…í™•í•˜ê²Œ ë³€ê²½
        print(f"SENSOR_SEARCH_ERROR ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ âŒ ì„¼ì„œ ë°ì´í„° ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. 'sensor_data' ì»¬ë ‰ì…˜ì˜ 'Product Category' í•„ë“œ ê°’ê³¼ '{product_type}' ì¼ì¹˜ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return []
    

#ì»¬ëŸ¼ì •ë³´
def get_columns_for_product(product_type: str,top_k: int = 20):
    """Qdrantì—ì„œ íŠ¹ì • ì œí’ˆêµ°ì˜ ìƒì„¸ í•„ë“œ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    print(f"ğŸ”© Getting column info for product_type='{product_type}'...")
    qdrant = get_qdrant_client()
    
    search_filter = Filter(
    must=[
        FieldCondition(
            key="product_type",
            match=MatchValue(value=product_type)
        )
    ]
)
    
    found_points, _ = qdrant.scroll(
        collection_name="product_metadata",
        scroll_filter=search_filter,
        limit=top_k,
        with_payload=True
    )
    
    if found_points:
        # í˜ì´ë¡œë“œì—ì„œ 'fields' ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        return found_points[0].payload.get("fields", {})
    else:
        # ì¼ì¹˜í•˜ëŠ” ì œí’ˆ ì •ë³´ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        return {}
    

def run_data_retriever(keyword: str, date_range_str: str | None, product_type: str | None):
    """
    Data Retriever ì—ì´ì „íŠ¸ì˜ ì „ì²´ ì‘ì—…ì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜í•©ë‹ˆë‹¤.
    í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬ëœ í‚¤ì›Œë“œ, ê¸°ê°„, ì œí’ˆêµ°ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    print(f"âœ… [Agent Called] run_data_retriever: keyword='{keyword}', date_range_str='{date_range_str}', product_type='{product_type}'")
    
    # 1. ë‚ ì§œ ë²”ìœ„ íŒŒì‹±
    parsed_date_range = parse_natural_date(date_range_str) if date_range_str else None

    # 2. í‚¤ì›Œë“œ í™•ì¥ (ì´ì œ LLMìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œí•  í•„ìš” ì—†ì´ ë°›ì€ í‚¤ì›Œë“œë¥¼ ë°”ë¡œ í™•ì¥í•©ë‹ˆë‹¤)
    # ì—¬ëŸ¬ í‚¤ì›Œë“œë¥¼ ì…ë ¥ë°›ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    keywords_list = [k.strip() for k in keyword.split(',') if k.strip()]
    if not keywords_list: # í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì›ë³¸ í‚¤ì›Œë“œ ìì²´ë¥¼ ì‚¬ìš©
        keywords_list = [keyword]

    all_expanded_keywords = []
    for kw in keywords_list:
        all_expanded_keywords.extend(expand_keywords(kw, product_type))
    # ì¤‘ë³µ ì œê±°
    all_expanded_keywords = list(set(all_expanded_keywords))
    
    print(f"âœ… Extracted & Expanded Keywords: {all_expanded_keywords}")
    print(f"âœ… Parsed Date Range: {parsed_date_range}")
    print(f"âœ… Product Type: {product_type}")

    # 3. ì›¹/ì†Œë¹„ì ë°ì´í„° ê²€ìƒ‰ (RRF)
    web_results = run_rrf_search(all_expanded_keywords, date_range=parsed_date_range)

    # 4. ë‚´ë¶€ ì œí’ˆ ë°ì´í„° ê²€ìƒ‰
    product_results = fetch_product_context(product_type)

    # 5. ì„¼ì„œ ë°ì´í„° ê²€ìƒ‰ (product_typeì´ ìˆì„ ê²½ìš°)
    sensor_data_results = fetch_sensor_context(product_type)

    #ì»¬ëŸ¼ ì •ë³´ ê²€ìƒ‰
    columns_product = get_columns_for_product(product_type)


    # 6. ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì— ì €ì¥í•  í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ê°€ê³µ
    return {
        "retrieved_data": {
            "query": keyword, # ì‚¬ìš©ì ì…ë ¥ ì›ë³¸ í‚¤ì›Œë“œë¥¼ queryë¡œ ì €ì¥
            "expanded_keywords": all_expanded_keywords, # í™•ì¥ëœ í‚¤ì›Œë“œë„ ì €ì¥
            "web_results": web_results,
        },
        "columns_product": columns_product,
        "sensor_data": sensor_data_results,
        "product_data": product_results,
        "product_type": product_type,
    }
