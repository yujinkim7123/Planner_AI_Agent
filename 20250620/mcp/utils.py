# agents/utils.py
import torch
from sentence_transformers import SentenceTransformer, models
from qdrant_client import QdrantClient
from openai import OpenAI, AsyncOpenAI # AsyncOpenAI ì„í¬íŠ¸ë„ ì¤‘ìš”í•©ë‹ˆë‹¤!
import os 
from datetime import datetime, date, timedelta
from dateutil.relativedelta import relativedelta
import re
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from qdrant_client.http.models import Filter, FieldCondition, MatchValue 
sentiment_analyzer = None 

# ëª¨ë¸ê³¼ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì €ì¥í•  ì „ì—­ ë³€ìˆ˜
meaning_model = None
topic_model = None
qdrant_client = None
openai_client = None


def get_sentiment_analyzer():
    """
    [ì‹ ê·œ] ì‚¬ì „ í•™ìŠµëœ í•œêµ­ì–´ ê°ì„± ë¶„ë¥˜ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    Hugging Faceì˜ pipelineì„ ì‚¬ìš©í•˜ì—¬ ì‰½ê²Œ êµ¬í˜„í•©ë‹ˆë‹¤.
    """
    global sentiment_analyzer
    if sentiment_analyzer is None:
        print("ğŸŒ€ Loading pre-trained sentiment analysis model...")
        
        # Define the local path to your model files
        local_model_path = "C:/Users/User/DIC_Project/persona_mcp_server/agents/models/bert-nsmc" 
        
        try:
            # Load the tokenizer from your local path
            tokenizer = AutoTokenizer.from_pretrained(local_model_path)
            model = AutoModelForSequenceClassification.from_pretrained(local_model_path)

            # 2. pipelineì— ë¡œì»¬ ëª¨ë¸ê³¼ tokenizer ì „ë‹¬
            sentiment_analyzer = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

        except Exception as e:
            print(f"âŒ Error loading sentiment analysis model from local path: {e}")
            sentiment_analyzer = None # Ensure it remains None if loading fails
    return sentiment_analyzer

def get_embedding_models():
    """
    ì˜ë¯¸ ê²€ìƒ‰(e5-large) ëª¨ë¸ê³¼ ì£¼ì œ ê²€ìƒ‰(ko-sbert) ëª¨ë¸ì„ ëª¨ë‘ ë¡œë“œí•©ë‹ˆë‹¤.
    ì´ë¯¸ ë¡œë“œë˜ì—ˆë‹¤ë©´ ê¸°ì¡´ ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    global meaning_model, topic_model
    if meaning_model is None or topic_model is None:
        print("ğŸŒ€ Loading embedding models (meaning & topic)...")
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # 1. Meaning Model ë¡œë“œ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
        meaning_model = SentenceTransformer(
            modules=[models.Transformer("intfloat/e5-large"), models.Pooling(1024, pooling_mode_mean_tokens=True)],
            device=device
        )
        
        # 2. Topic Model ë¡œë“œ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
        topic_model = SentenceTransformer("jhgan/ko-sbert-nli", device=device)
        
        print("âœ… All embedding models loaded.")
        
    return meaning_model, topic_model

def get_qdrant_client():
    """Qdrant í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    global qdrant_client
    if qdrant_client is None:
        print("ğŸŒ€ Initializing Qdrant client...")
        qdrant_client = QdrantClient(host="localhost", port=6333)
        print("âœ… Qdrant client initialized.")
    return qdrant_client

def get_openai_client(async_client=False):
    """
    [ê°œì„ ë¨] OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ìµœì´ˆ í˜¸ì¶œ ì‹œ, í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ì½ì–´ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    global openai_client
    if openai_client is None:
        print("ğŸŒ€ Initializing OpenAI client...")
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("'.env' íŒŒì¼ì— OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        openai_client = OpenAI(api_key=api_key) # í•­ìƒ ë™ê¸° í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•˜ê³  ì „ì—­ ë³€ìˆ˜ì— ì €ì¥
    return openai_client # ì €ì¥ëœ ë™ê¸° í´ë¼ì´ì–¸íŠ¸ë¥¼ ë°˜í™˜


    
def parse_natural_date(text: str | None) -> tuple | None:
    """
    [ìµœì¢… ìˆ˜ì •] '1ë…„ê°„', '3ê°œì›”ê°„' ë“±ì˜ í‘œí˜„ë„ ì¸ì‹í•˜ë„ë¡ ì •ê·œí‘œí˜„ì‹ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.
    """
    if not text:
        return None

    today = datetime.now()
    text = text.lower()
    
    match = re.search(r'(?:ìµœê·¼|ì§€ë‚œ)\s*(\d+)\s*(ê°œì›”|ë‹¬|ë…„|ì£¼|ì¼)ê°„?', text)
    if match:
        num, unit = int(match.group(1)), match.group(2)
        end_date = today.date()
        if 'ë…„' in unit:
            start_date = (today - timedelta(days=num*365)).date()
        elif 'ì£¼' in unit:
            start_date = (today - timedelta(days=num*7)).date()
        elif 'ì¼' in unit:
            start_date = (today - timedelta(days=num)).date()
        else: # ê°œì›” ë˜ëŠ” ë‹¬
            start_date = (today - timedelta(days=num*30)).date()
        return start_date, end_date

    # ë‹¤ë¥¸ íŒ¨í„´ë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
    if 'ì˜¬í•´' in text or 'ì´ë²ˆ ë…„ë„' in text:
        return datetime(today.year, 1, 1).date(), today.date()
    if 'ì‘ë…„' in text:
        last_year = today.year - 1
        return datetime(last_year, 1, 1).date(), datetime(last_year, 12, 31).date()

    if 'ì´ë²ˆ ë‹¬' in text:
        return today.replace(day=1).date(), today.date()
    if 'ì§€ë‚œ ë‹¬' in text:
        first_day_of_current_month = today.replace(day=1)
        last_day_of_last_month = first_day_of_current_month - timedelta(days=1)
        first_day_of_last_month = last_day_of_last_month.replace(day=1)
        return first_day_of_last_month.date(), last_day_of_last_month.date()

    if 'ì–´ì œ' in text:
        yesterday = (today - timedelta(days=1)).date()
        return yesterday, yesterday
    if 'ì˜¤ëŠ˜' in text:
        return today.date(), today.date()
        
    return None