# agents/service_creator.py

import json
from .utils import get_openai_client
from .data_retriever import fetch_product_context, fetch_sensor_context, get_columns_for_product
from qdrant_client.http.models import Filter, FieldCondition, MatchValue 
def _get_json_format_prompt(product_type: str | None) -> str:
    # ... (ì´ í•¨ìˆ˜ëŠ” ê¸°ì¡´ê³¼ ë™ì¼, ë³€ê²½ ì—†ìŒ) ...
    tip_field = ""
    if not product_type:
        tip_field = ',\n      "tip": "íŒ: íŠ¹ì • LG ì œí’ˆêµ°ì„ ì§€ì •í•˜ë©´ í•´ë‹¹ ì œí’ˆì— ë” ìµœì í™”ëœ ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."'

    return f"""
    ```json
    {{
      "service_ideas": [
        {{
          "service_name": "AI ìœ¡ì•„ ìœ„ìƒ ì»¨ì„¤í„´íŠ¸",
          "description": "í˜ë¥´ì†Œë‚˜ì˜ ì•„ì´ ì—°ë ¹ê³¼ ê±´ê°• ìƒíƒœ(ì˜ˆ: ì•„í† í”¼)ì— ë§ì¶°, ì˜ë¥˜, ì¥ë‚œê°, ì‹ê¸° ë“±ì˜ ìµœì  ì‚´ê·  ì£¼ê¸°ì™€ ë°©ë²•ì„ ì•Œë ¤ì£¼ê³  ê°€ì „ì œí’ˆ(ì„¸íƒê¸°, ê±´ì¡°ê¸° ë“±)ì„ ìë™ìœ¼ë¡œ ì œì–´í•´ì£¼ëŠ” êµ¬ë…í˜• ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.",
          "solved_pain_points": [
            "ì‚´ê·  ê¸°ëŠ¥ì˜ ì‹¤ì œ íš¨ê³¼ë¥¼ ëˆˆìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ì—†ì–´ ë¶ˆì•ˆí•˜ë‹¤",
            "ë§¤ë²ˆ ì˜·ì„ ì‚¶ëŠ” ê²ƒì€ ë²ˆê±°ë¡­ê³  ì˜·ê°ì´ ìƒí• ê¹Œ ê±±ì •ëœë‹¤"
          ],
          "service_scalability": "ì´ˆê¸°ì—ëŠ” ThinQ ì•±ì˜ ê¸°ëŠ¥ìœ¼ë¡œ ì œê³µí•˜ê³ , ì¶”í›„ ì˜ìœ ì•„ ê±´ê°• ë°ì´í„°ë¥¼ ì—°ë™í•œ í”„ë¦¬ë¯¸ì—„ ìœ ë£Œ êµ¬ë… ëª¨ë¸ë¡œ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì¶•ì ëœ ë°ì´í„°ëŠ” ìƒˆë¡œìš´ ì˜ìœ ì•„ ì „ë¬¸ ê°€ì „ ê°œë°œì˜ ê¸°ë°˜ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        }}
      ]{tip_field}
    }}
    ```
    """

def _build_service_creation_prompt(persona: dict, product_type: str | None, device_columns: dict, feature_docs: list, sensor_columns: list, num_ideas: int) -> str:
    """ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ ìƒì„±ì„ ìœ„í•œ LLM í”„ë¡¬í”„íŠ¸ë¥¼ ë™ì ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤."""
    prompt_header = f"""
    ë‹¹ì‹ ì€ LGì „ìì˜ ì‹ ì‚¬ì—… ê¸°íšì„ ì´ê´„í•˜ëŠ” ìµœê³ ì˜ ì„œë¹„ìŠ¤ ì „ëµê°€ì…ë‹ˆë‹¤.
    ê³ ê° ë°ì´í„°ì— ê¸°ë°˜í•˜ì—¬, ë‹¨ê³„ë³„ë¡œ ìƒê°(Think step-by-step)í•´ì„œ ê¸°ì¡´ì˜ í‹€ì„ ê¹¨ëŠ” í˜ì‹ ì ì´ë©´ì„œë„ ì‹¤í˜„ ê°€ëŠ¥í•œ ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ë¥¼ ë§Œë“œëŠ” ë° íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    """
    
    persona_data_prompt = f"""
    ### [ë¶„ì„ ëŒ€ìƒ í˜ë¥´ì†Œë‚˜ ì •ë³´]
    - ì´ë¦„: {persona.get('name')} ({persona.get('title')})
    - ì¸êµ¬í†µê³„: {persona.get('demographics')}
    - í•µì‹¬ ë‹ˆì¦ˆ ë° ëª©í‘œ: {persona.get('needs_and_goals')}
    - **í•µì‹¬ ë¶ˆí¸í•¨ (Pain Points): {persona.get('pain_points')}**
    - ë™ê¸°ë¶€ì—¬ ë¬¸êµ¬: "{persona.get('motivating_quote')}"
    """
    
    product_context_prompt = ""
    if product_type:
        product_context_prompt = f"""
    ### [ê¸°ì¡´ ì œí’ˆ ë° ê¸°ëŠ¥ ì •ë³´ (ì œí’ˆêµ°: {product_type})]
    - ì œí’ˆ ìƒì„¸ ë°ì´í„° í•„ë“œ: {json.dumps(device_columns, ensure_ascii=False)}
    - ê´€ë ¨ ê¸°ëŠ¥ ë¬¸ì„œ ìš”ì•½: {json.dumps(feature_docs, ensure_ascii=False)}
    - **ì—°ê´€ ì„¼ì„œ ë°ì´í„° (ìƒ˜í”Œ): {json.dumps(sensor_columns, ensure_ascii=False)}**
    """
    else:
        product_context_prompt = """
    ### [ê¸°ì¡´ ì œí’ˆ ë° ê¸°ëŠ¥ ì •ë³´]
    - (ì§€ì •ëœ ì œí’ˆêµ° ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.)
    """
    instructions_prompt = f"""
    ### [ì§€ì‹œì‚¬í•­]
    ìœ„ í˜ë¥´ì†Œë‚˜ì™€ ì œí’ˆ/ì„¼ì„œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì„ ë°˜ë“œì‹œ ë§Œì¡±í•˜ëŠ” **ìƒˆë¡œìš´ ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ {num_ideas}ê°œ**ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.

    1.  **Pain Point í•´ê²°**: ê° ì•„ì´ë””ì–´ëŠ” í˜ë¥´ì†Œë‚˜ì˜ Pain Point ì¤‘ í•˜ë‚˜ ì´ìƒì„ ëª…í™•í•˜ê³  ì§ì ‘ì ìœ¼ë¡œ í•´ê²°í•´ì•¼ í•©ë‹ˆë‹¤.
    2.  **ë°ì´í„° í™œìš©**: ì œì•ˆí•˜ëŠ” ì„œë¹„ìŠ¤ì˜ í•µì‹¬ ê¸°ëŠ¥ì´ **ì–´ë–¤ ì œí’ˆ ë˜ëŠ” ì„¼ì„œ ë°ì´í„°**ë¥¼ ì–´ë–»ê²Œ í™œìš©í•˜ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤. íŠ¹íˆ, ì„¼ì„œ ë°ì´í„°ë¥¼ ì¡°í•©í•˜ì—¬ ìƒˆë¡œìš´ ê°€ì¹˜ë¥¼ ë§Œë“œëŠ” ë°©ì•ˆì„ ì ê·¹ì ìœ¼ë¡œ ëª¨ìƒ‰í•´ì£¼ì„¸ìš”.
    3.  **ì„œë¹„ìŠ¤ í™•ì¥ì„± (Scalability)**: ì œì•ˆí•˜ëŠ” ì„œë¹„ìŠ¤ê°€ ë¯¸ë˜ì— ì–´ë–»ê²Œ ì„±ì¥í•˜ê³  í™•ì¥ë  ìˆ˜ ìˆëŠ”ì§€ êµ¬ì²´ì ì¸ ë°©ì•ˆì„ ë°˜ë“œì‹œ í¬í•¨í•´ì£¼ì„¸ìš”. (ì˜ˆ: ë‹¤ë¥¸ ì œí’ˆ ì—°ë™, êµ¬ë… ëª¨ë¸ ë°œì „, ë°ì´í„° ê¸°ë°˜ ê°œì¸í™”, í”Œë«í¼í™” ë“±)
    4.  **ê²°ê³¼ í˜•ì‹**: ì•„ë˜ JSON êµ¬ì¡°ë¥¼ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬ ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ê²°ê³¼ë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
    {_get_json_format_prompt(product_type)}
    """
    
    return prompt_header + persona_data_prompt + product_context_prompt + instructions_prompt
# [ìˆ˜ì •] ê¸°ì¡´ í•¨ìˆ˜ë¥¼ ë¦¬íŒ©í† ë§ëœ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
def create_service_ideas(workspace: dict, persona_name: str, num_ideas: int = 3):
    """(ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì— ì €ì¥ëœ) ì§€ì •ëœ í˜ë¥´ì†Œë‚˜ì˜ Pain Pointë¥¼ í•´ê²°í•˜ëŠ” ìƒˆë¡œìš´ ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
   
    client = get_openai_client()
    artifacts = workspace.get("artifacts", {})

    all_personas = artifacts.get("personas")
    if not all_personas:
        return {"error": "ì„œë¹„ìŠ¤ë¥¼ ìƒì„±í•˜ë ¤ë©´ ë¨¼ì € 'í˜ë¥´ì†Œë‚˜ ìƒì„±'ì„ í†µí•´ ê³ ê° í˜ë¥´ì†Œë‚˜ë¥¼ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤."}

    selected_persona = next((p for p in all_personas if p.get("name") == persona_name), None)
    if not selected_persona:
        available_names = ", ".join([f"'{p.get('name')}'" for p in all_personas])
        return {"error": f"'{persona_name}' í˜ë¥´ì†Œë‚˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ í˜ë¥´ì†Œë‚˜: [{available_names}]"}

    workspace["artifacts"]["selected_persona"] = selected_persona
    print(f"ğŸ“Œ Persona '{persona_name}' has been set as the selected persona.")

    artifacts = workspace.get("artifacts", {})
    product_type = artifacts.get("product_type")
    
    device_columns = {}
    product_docs = []
    sensor_columns = []
    if product_type:
        print(f"ğŸ” ì œí’ˆêµ° '{product_type}'ì— ëŒ€í•œ ê¸°ì¡´ ì •ë³´ í™œìš© ì¤‘...")
        if not artifacts.get("product_data"):
            product_docs = fetch_product_context(product_type)
            workspace["artifacts"]["product_data"] = product_docs
        else:   
            product_docs = artifacts.get("product_data")
        if not artifacts.get("product_data"):    
            device_columns = get_columns_for_product(product_type)
            workspace["artifacts"]["columns_product"] = device_columns
        else:
            device_columns = artifacts.get("columns_product")
        if not artifacts.get("sensor_data"):    
            sensor_columns = fetch_sensor_context(product_type)
            workspace["artifacts"]["sensor_data"] = sensor_columns
        else:
            sensor_columns = artifacts.get("sensor_data")
        
    final_prompt = _build_service_creation_prompt(selected_persona, product_type, device_columns, product_docs,sensor_columns, num_ideas)

    try:
        res = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": final_prompt}],
            response_format={"type": "json_object"}
        )
        service_idea_results = json.loads(res.choices[0].message.content)
        workspace["artifacts"]["service_ideas"] = service_idea_results
        return {"service_ideas_result": service_idea_results}
    except Exception as e:
        print(f"âŒ ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {"error": f"ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"}

#ìˆ˜ë™ ì…ë ¥ì„ ìœ„í•œ ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ í•¨ìˆ˜
# def create_service_ideas_from_manual_input(workspace: dict, persona_description: str):
#     """(í¼ ì…ë ¥) ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥í•œ êµ¬ì¡°í™”ëœ í˜ë¥´ì†Œë‚˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
#     print(f"âœ… [Service Creator] Running Service Idea Generation from structured form input...")

#     selected_persona = persona_description
#     print(f"ğŸ“ ì…ë ¥ëœ í˜ë¥´ì†Œë‚˜ ì •ë³´: {selected_persona}")

#     if "personas" not in workspace["artifacts"]:
#         workspace["artifacts"]["personas"] = []
#     workspace["artifacts"]["personas"].append(selected_persona)
#     workspace["artifacts"]["selected_persona"] = selected_persona
#     print(f"ğŸ“Œ Manually described persona has been created and set as the selected persona.")

    
def modify_service_ideas(workspace: dict, modification_request: str):
    """(ìˆ˜ì •) ê¸°ì¡´ì— ìƒì„±ëœ ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ë¥¼ ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ìˆ˜ì •í•©ë‹ˆë‹¤."""
    print(f"âœ… [Service Creator] Running Service Idea Modification: '{modification_request}'")
    client = get_openai_client()
    artifacts = workspace.get("artifacts", {})

    existing_ideas = artifacts.get("service_ideas")
    selected_persona = artifacts.get("selected_persona")
    if not existing_ideas or not selected_persona:
        return {"error": "ìˆ˜ì •í•  ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ê°€ ì—†ê±°ë‚˜, ëŒ€ìƒ í˜ë¥´ì†Œë‚˜ê°€ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    product_type = artifacts.get("product_type")

    if product_type:
        print(f"ğŸ” ì œí’ˆêµ° '{product_type}'ì— ëŒ€í•œ ê¸°ì¡´ ì •ë³´ í™œìš© ì¤‘...")
        if not artifacts.get("product_data"):
            product_docs = fetch_product_context(product_type)
            workspace["artifacts"]["product_data"] = product_docs
        else:   
            product_docs = artifacts.get("product_data")
        if not artifacts.get("product_data"):    
            device_columns = get_columns_for_product(product_type)
            workspace["artifacts"]["columns_product"] = device_columns
        else:
            device_columns = artifacts.get("columns_product")
        if not artifacts.get("sensor_data"):    
            sensor_columns = fetch_sensor_context(product_type)
            workspace["artifacts"]["sensor_data"] = sensor_columns
        else:
            sensor_columns = artifacts.get("sensor_data")

    # ìˆ˜ì •ìš© í”„ë¡¬í”„íŠ¸
    technical_context_prompt = ""
    if product_type:
        technical_context_prompt = f"""
    ### [ì°¸ê³ ìš© ê¸°ìˆ  ë°ì´í„°]
    - ì œí’ˆ ìƒì„¸ ë°ì´í„° í•„ë“œ: {json.dumps(device_columns, ensure_ascii=False)}
    - ê´€ë ¨ ê¸°ëŠ¥ ë¬¸ì„œ ìš”ì•½: {json.dumps(product_docs, ensure_ascii=False)}
    - ì—°ê´€ ì„¼ì„œ ë°ì´í„° (ìƒ˜í”Œ): {json.dumps(sensor_columns, ensure_ascii=False)}
    - ì œí’ˆêµ° : {product_type}
    """

    # ğŸ“Œ [ìˆ˜ì •] 3. ìˆ˜ì •ìš© í”„ë¡¬í”„íŠ¸ì— ê¸°ìˆ  ì»¨í…ìŠ¤íŠ¸ì™€ ì§€ì‹œì‚¬í•­ ì¶”ê°€
    prompt = f"""
    ë‹¹ì‹ ì€ ìµœê³ ì˜ ì„œë¹„ìŠ¤ ì „ëµê°€ì…ë‹ˆë‹¤. ë‹¨ê³„ë³„ë¡œ ìƒê°(Think step-by-step)í•˜ì—¬, ì•„ë˜ 'ê¸°ì¡´ ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´'ë¥¼ 'ì‚¬ìš©ì ìˆ˜ì • ìš”ì²­'ì— ë§ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”. 
    ìˆ˜ì •ì˜ ê¸°ë°˜ì´ ë˜ëŠ” í˜ë¥´ì†Œë‚˜ ë° ê¸°ìˆ  ë°ì´í„°ë„ ì°¸ê³ í•˜ì„¸ìš”.
    ê·¸ë¦¬ê³  ìˆ˜ì •ìš”ì²­ë˜ì§€ ì•Šì€ ë¶€ë¶„ì€ ì ˆëŒ€ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”.

    ### ê¸°ë°˜ í˜ë¥´ì†Œë‚˜ ì •ë³´
    {json.dumps(selected_persona, ensure_ascii=False, indent=2)}
    
    {technical_context_prompt}

    ### ê¸°ì¡´ ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´
    {json.dumps(existing_ideas, ensure_ascii=False, indent=2)}

    ### ì‚¬ìš©ì ìˆ˜ì • ìš”ì²­
    "{modification_request}"

    ### ì§€ì‹œì‚¬í•­
    - 'ì‚¬ìš©ì ìˆ˜ì • ìš”ì²­'ì„ ì™„ë²½í•˜ê²Œ ë°˜ì˜í•˜ì—¬ ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ ì „ì²´ë¥¼ ë‹¤ì‹œ ìƒì„±í•´ì£¼ì„¸ìš”.
    - **(ì¤‘ìš”)** ìˆ˜ì •ì‚¬í•­ì„ ë°˜ì˜í•  ë•Œ, ìœ„ì— ì œì‹œëœ **[ì°¸ê³ ìš© ê¸°ìˆ  ë°ì´í„°]**ë¥¼ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ì•„ì´ë””ì–´ë¥¼ ê¸°ìˆ ì ìœ¼ë¡œ ë” êµ¬ì²´í™”í•˜ê±°ë‚˜ ë³´ê°•í•´ì£¼ì„¸ìš”.
    - **ê²°ê³¼ í˜•ì‹**: ì•„ë˜ JSON êµ¬ì¡°ë¥¼ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬ ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ê²°ê³¼ë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
    {_get_json_format_prompt(product_type)}
    """
    try:
        res = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        service_idea_results = json.loads(res.choices[0].message.content)
        new_ideas = service_idea_results.get("service_ideas", [])

        # 1. ê¸°ì¡´ ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. ë§Œì•½ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.
        existing_ideas_obj = workspace["artifacts"].get("service_ideas") or {"service_ideas": []}
        existing_ideas = existing_ideas_obj.get("service_ideas", [])

        # 2. ê¸°ì¡´ ì•„ì´ë””ì–´ë¥¼ 'service_name'ì„ keyë¡œ ì‚¬ìš©í•˜ëŠ” dict(ideas_map)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        ideas_map = {idea["service_name"]: idea for idea in existing_ideas}

        # 3. ìƒˆë¡œ ìƒì„±ëœ ì•„ì´ë””ì–´ ëª©ë¡ì„ í•˜ë‚˜ì”© í™•ì¸í•˜ë©° ë§µì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        for idea in new_ideas:
            idea_name = idea.get("service_name")
            if idea_name:
                ideas_map[idea_name] = idea # ì´ë¦„ì´ ê°™ìœ¼ë©´ êµì²´, ì—†ìœ¼ë©´ ì¶”ê°€

        # 4. ì—…ë°ì´íŠ¸ëœ dictë¥¼ ë‹¤ì‹œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ workspaceì— ì €ì¥í•©ë‹ˆë‹¤.
        #    ì´ë•Œ {"service_ideas": [ ... ]} êµ¬ì¡°ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
        workspace["artifacts"]["service_ideas"] = {"service_ideas": list(ideas_map.values())}

        # 5. í•¨ìˆ˜ í˜¸ì¶œ ê²°ê³¼ë¡œ ìƒˆë¡œ ìƒì„±ëœ ì•„ì´ë””ì–´ ì •ë³´ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        return {"service_ideas_result": service_idea_results}
    except Exception as e:
        return {"error": f"ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜: {e}"}